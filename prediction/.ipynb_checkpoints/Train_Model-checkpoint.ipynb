{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1381d537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575902dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('Cleaned_KL_Housing_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad37b7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Separate features and target variable\n",
    "# X = df.drop('Price', axis=1)\n",
    "# y = df['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93780ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # One-hot encode categorical features\n",
    "# X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2c9ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb9bb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create and train the model\n",
    "# lr_clf = RandomForestRegressor()\n",
    "# lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657f865e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# score = lr_clf.score(X_test, y_test)\n",
    "# print(f'Model Score: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b6e6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Load the dataset\n",
    "# data = {\n",
    "#     'Location': ['Bukit Bintang'],\n",
    "#     'Rooms': [5],\n",
    "#     'Bathrooms': [5],\n",
    "#     'Car Parks': [2],\n",
    "#     'Property Type': ['Serviced Residence'],\n",
    "#     'Furnishing': ['Partly Furnished'],\n",
    "#     'Build Type': ['Built-up'],\n",
    "#     'Sqft': [4157]\n",
    "# }\n",
    "# new_data = pd.DataFrame(data)\n",
    "\n",
    "# # One-hot encode categorical features\n",
    "# new_data = pd.get_dummies(new_data)\n",
    "\n",
    "# # Load the training dataset to get the feature names\n",
    "# df = pd.read_csv('Cleaned_KL_Housing_Dataset.csv')\n",
    "# X_train = pd.get_dummies(df.drop('Price', axis=1))\n",
    "\n",
    "# # Align the columns of the prediction dataset with the columns of the training dataset\n",
    "# new_data = new_data.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# # Make predictions\n",
    "# predicted_prices = lr_clf.predict(new_data)\n",
    "\n",
    "# print(\"Predicted Price:\", predicted_prices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7c4e88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('Cleaned_KL_Housing_Dataset.csv')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop('Price', axis=1)\n",
    "y = df['Price']\n",
    "\n",
    "# One-hot encode categorical features (if any)\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameter tuning using Grid Search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=RandomForestRegressor(), param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters from Grid Search\n",
    "best_params = grid_search.best_params_\n",
    "print(f'Best Parameters: {best_params}')\n",
    "\n",
    "# Train the model with best parameters\n",
    "best_rf = RandomForestRegressor(**best_params)\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = best_rf.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "score = best_rf.score(X_test, y_test)\n",
    "\n",
    "print(f'Model Score: {score}')\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adddc7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(best_rf, 'best_rf_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14be5684",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the trained model\n",
    "best_rf_model = joblib.load('best_rf_model.pkl')\n",
    "\n",
    "# New data for prediction (example user input)\n",
    "data = {\n",
    "    'Location': ['KLCC'],\n",
    "    'Rooms': [4],\n",
    "    'Bathrooms': [4],\n",
    "    'Car Parks': [2],\n",
    "    'Property Type': ['Serviced Residence'],\n",
    "    'Furnishing': ['Fully Furnished'],\n",
    "    'Build Type': ['Built-up'],\n",
    "    'Sqft': [1378]\n",
    "}\n",
    "new_data = pd.DataFrame(data)\n",
    "\n",
    "# One-hot encode categorical features\n",
    "new_data = pd.get_dummies(new_data)\n",
    "\n",
    "# Ensure the new data has the same columns as the training data\n",
    "missing_cols = set(X.columns) - set(new_data.columns)\n",
    "for col in missing_cols:\n",
    "    new_data[col] = 0\n",
    "new_data = new_data[X.columns]\n",
    "\n",
    "# Make predictions\n",
    "predicted_prices = best_rf_model.predict(new_data)\n",
    "\n",
    "print(\"Predicted Price:\", predicted_prices[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8213b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = best_rf.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "score = best_rf.score(X_test, y_test)\n",
    "\n",
    "print(f'Model Score: {score}')\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb6d5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "residuals = y_test - y_pred\n",
    "plt.scatter(y_pred, residuals)\n",
    "plt.hlines(y=0, xmin=min(y_pred), xmax=max(y_pred), colors='r')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals vs Predicted Values')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6a51d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(best_rf, X, y, cv=5, scoring='neg_mean_squared_error', train_sizes=np.linspace(0.1, 1.0, 10))\n",
    "train_scores_mean = (-train_scores).mean(axis=1)\n",
    "test_scores_mean = (-test_scores).mean(axis=1)\n",
    "\n",
    "plt.plot(train_sizes, train_scores_mean, label='Training error')\n",
    "plt.plot(train_sizes, test_scores_mean, label='Validation error')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Training size')\n",
    "plt.legend()\n",
    "plt.title('Learning Curves')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96952025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.xlabel('Actual Prices')\n",
    "plt.ylabel('Predicted Prices')\n",
    "plt.title('Actual vs Predicted Prices')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red')  # Diagonal line\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da68f8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# import joblib\n",
    "\n",
    "# # Load dataset\n",
    "# df = pd.read_csv('Cleaned_KL_Housing_Dataset.csv')\n",
    "\n",
    "# # Separate features and target variable\n",
    "# X = df.drop('Price', axis=1)\n",
    "# y = df['Price']\n",
    "\n",
    "# # Define preprocessing for categorical features\n",
    "# categorical_features = X.select_dtypes(include=['object']).columns\n",
    "# categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# # Create preprocessing pipeline\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('cat', categorical_transformer, categorical_features)\n",
    "#     ],\n",
    "#     remainder='passthrough'\n",
    "# )\n",
    "\n",
    "# # Define the model pipeline\n",
    "# model_pipeline = Pipeline(steps=[\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('regressor', RandomForestRegressor())\n",
    "# ])\n",
    "\n",
    "# # Split data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Train the model\n",
    "# model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# # Save the model pipeline\n",
    "# joblib.dump(model_pipeline, 'prediction_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59cd0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# # Load the saved model pipeline\n",
    "# loaded_model_pipeline = joblib.load('prediction_model.pkl')\n",
    "\n",
    "# # Use the model to make predictions\n",
    "# y_pred = loaded_model_pipeline.predict(X_test)\n",
    "\n",
    "# # Evaluate the model performance\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "# print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "# print(f\"R-squared: {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fc5e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import joblib\n",
    "\n",
    "# # Load the trained model\n",
    "# model_pipeline = joblib.load('prediction_model.pkl')\n",
    "\n",
    "# # New data for prediction\n",
    "# data = {\n",
    "#     'Location': ['KLCC'],\n",
    "#     'Rooms': [3],\n",
    "#     'Bathrooms': [3],\n",
    "#     'Car Parks': [2],\n",
    "#     'Property Type': ['Serviced Residence'],\n",
    "#     'Furnishing': ['Fully Furnished'],\n",
    "#     'Build Type': ['Built-up'],\n",
    "#     'Sqft': [1330]\n",
    "# }\n",
    "# new_data = pd.DataFrame(data)\n",
    "\n",
    "# # Make predictions\n",
    "# predicted_prices = model_pipeline.predict(new_data)\n",
    "\n",
    "# print(\"Predicted Price:\", predicted_prices[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e70c85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FINAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e64bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('Cleaned_KL_Housing_Dataset.csv')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop('Price', axis=1)\n",
    "y = df['Price']\n",
    "\n",
    "# One-hot encode categorical features\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Log transformation of the target variable to reduce skewness\n",
    "y = np.log1p(y)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Align the train and test data\n",
    "X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# Feature engineering: Adding interaction terms or polynomial features (optional)\n",
    "# Example: X_train['Sqft_Rooms'] = X_train['Sqft'] * X_train['Rooms']\n",
    "# Example: X_test['Sqft_Rooms'] = X_test['Sqft'] * X_test['Rooms']\n",
    "\n",
    "# Hyperparameter tuning using Grid Search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=RandomForestRegressor(), param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters from Grid Search\n",
    "best_params = grid_search.best_params_\n",
    "print(f'Best Parameters: {best_params}')\n",
    "\n",
    "# Train the model with best parameters\n",
    "best_rf = RandomForestRegressor(**best_params)\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(best_rf, 'best_rf_model.pkl')\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Inverse the log transformation\n",
    "y_test_exp = np.expm1(y_test)\n",
    "y_pred_exp = np.expm1(y_pred)\n",
    "\n",
    "mse = mean_squared_error(y_test_exp, y_pred_exp)\n",
    "mae = mean_absolute_error(y_test_exp, y_pred_exp)\n",
    "score = best_rf.score(X_test, y_test)\n",
    "\n",
    "print(f'Model Score: {score}')\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8069eb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Load the trained model\n",
    "best_rf_model = joblib.load('best_rf_model.pkl')\n",
    "\n",
    "# New data for prediction (example user input)\n",
    "data = {\n",
    "    'Location': ['KLCC'],\n",
    "    'Rooms': [4],\n",
    "    'Bathrooms': [3],\n",
    "    'Car Parks': [2],\n",
    "    'Property Type': ['Serviced Residence'],\n",
    "    'Furnishing': ['Partly Furnished'],\n",
    "    'Build Type': ['Built-up'],\n",
    "    'Sqft': [2066]\n",
    "}\n",
    "new_data = pd.DataFrame(data)\n",
    "\n",
    "# One-hot encode categorical features\n",
    "new_data = pd.get_dummies(new_data)\n",
    "\n",
    "# Ensure the unseen data has the same columns as the training data\n",
    "missing_cols_unseen = set(best_rf.feature_names_in_) - set(unseen_df.columns)\n",
    "for col in missing_cols_unseen:\n",
    "    unseen_df[col] = 0\n",
    "unseen_df = unseen_df[best_rf.feature_names_in_]\n",
    "\n",
    "# Make predictions on unseen data\n",
    "unseen_pred_log = best_rf.predict(unseen_df)\n",
    "unseen_pred = np.expm1(unseen_pred_log)\n",
    "\n",
    "print(\"Predicted Price for Unseen Data:\", unseen_pred[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9626851d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification of Model Accuracy on Training Data\n",
    "train_pred = best_rf.predict(X_train)\n",
    "train_pred_exp = np.expm1(train_pred)\n",
    "y_train_exp = np.expm1(y_train)\n",
    "\n",
    "train_mse = mean_squared_error(y_train_exp, train_pred_exp)\n",
    "train_mae = mean_absolute_error(y_train_exp, train_pred_exp)\n",
    "train_score = best_rf.score(X_train, y_train)\n",
    "\n",
    "print(f'Training Data Model Score: {train_score}')\n",
    "print(f'Training Data Mean Squared Error: {train_mse}')\n",
    "print(f'Training Data Mean Absolute Error: {train_mae}')\n",
    "\n",
    "# Testing on Unseen Data\n",
    "unseen_data = {\n",
    "    'Location': ['KLCC'],\n",
    "    'Rooms': [4],\n",
    "    'Bathrooms': [4],\n",
    "    'Car Parks': [2],\n",
    "    'Property Type': ['Serviced Residence'],\n",
    "    'Furnishing': ['Fully Furnished'],\n",
    "    'Build Type': ['Built-up'],\n",
    "    'Sqft': [1378]\n",
    "}\n",
    "unseen_df = pd.DataFrame(unseen_data)\n",
    "\n",
    "# One-hot encode categorical features\n",
    "unseen_df = pd.get_dummies(unseen_df)\n",
    "\n",
    "# Ensure the unseen data has the same columns as the training data\n",
    "missing_cols_unseen = set(best_rf_model.feature_names_in_) - set(unseen_df.columns)\n",
    "for col in missing_cols_unseen:\n",
    "    unseen_df[col] = 0\n",
    "unseen_df = unseen_df[best_rf_model.feature_names_in_]\n",
    "\n",
    "# Make predictions on unseen data\n",
    "unseen_pred_log = best_rf_model.predict(unseen_df)\n",
    "unseen_pred = np.expm1(unseen_pred_log)\n",
    "\n",
    "print(\"Predicted Price for Unseen Data:\", unseen_pred[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e055cdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('Cleaned_KL_Housing_Dataset.csv')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop('Price', axis=1)\n",
    "y = df['Price']\n",
    "\n",
    "# One-hot encode categorical features\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Log transformation of the target variable to reduce skewness\n",
    "y = np.log1p(y)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Align the train and test data\n",
    "X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# Feature engineering: Adding interaction terms or polynomial features (optional)\n",
    "# Example: X_train['Sqft_Rooms'] = X_train['Sqft'] * X_train['Rooms']\n",
    "# Example: X_test['Sqft_Rooms'] = X_test['Sqft'] * X_test['Rooms']\n",
    "\n",
    "# Hyperparameter tuning using Grid Search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=RandomForestRegressor(), param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters from Grid Search\n",
    "best_params = grid_search.best_params_\n",
    "print(f'Best Parameters: {best_params}')\n",
    "\n",
    "# Train the model with best parameters\n",
    "best_rf = RandomForestRegressor(**best_params)\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(best_rf, 'best_rf_model.pkl')\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Inverse the log transformation\n",
    "y_test_exp = np.expm1(y_test)\n",
    "y_pred_exp = np.expm1(y_pred)\n",
    "\n",
    "mse = mean_squared_error(y_test_exp, y_pred_exp)\n",
    "mae = mean_absolute_error(y_test_exp, y_pred_exp)\n",
    "score = best_rf.score(X_test, y_test)\n",
    "\n",
    "print(f'Model Score: {score}')\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64bdcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting actual vs predicted prices for the training set\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(y_train_exp.values, label='Actual Prices', color='blue')\n",
    "plt.plot(train_pred_exp, label='Predicted Prices', color='red', linestyle='dashed')\n",
    "plt.title('Training Set: Actual vs Predicted Prices')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "\n",
    "# Plotting actual vs predicted prices for the testing set\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(y_test_exp.values, label='Actual Prices', color='blue')\n",
    "plt.plot(y_pred_exp, label='Predicted Prices', color='red', linestyle='dashed')\n",
    "plt.title('Testing Set: Actual vs Predicted Prices')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f23da0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
